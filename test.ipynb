{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, dayofweek, date_format\n",
    "from pyspark.sql.types import StructType as R, StructField as Fld, DoubleType as Dbl, DecimalType as Dec, StringType as Str, IntegerType as Int, DateType as Date, TimestampType as Ts\n",
    "from pyspark.sql.functions import monotonically_increasing_id, from_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "songsSchema = R([\n",
    "    Fld(\"num_songs\", Int()),\n",
    "    Fld(\"artist_id\", Str()),\n",
    "    Fld(\"artist_latitude\", Dec()),\n",
    "    Fld(\"artist_longitude\", Dec()),\n",
    "    Fld(\"artist_location\", Str()),\n",
    "    Fld(\"artist_name\", Str()),\n",
    "    Fld(\"song_id\", Str()),\n",
    "    Fld(\"title\", Str()),\n",
    "    Fld(\"duration\", Dbl()),\n",
    "    Fld(\"year\", Int()),\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = './data/'\n",
    "song_data = f\"{input_data}/song_data/*/*/*/*.json\"\n",
    "df = spark.read.json(song_data, schema=songsSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- num_songs: integer (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: decimal(10,0) (nullable = true)\n",
      " |-- artist_longitude: decimal(10,0) (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"songs_table\")\n",
    "songs_table = spark.sql('''\n",
    "    SELECT DISTINCT song_id, title, artist_id, year, duration\n",
    "    FROM songs_table\n",
    "''')\n",
    "songs_table = songs_table.dropDuplicates(['song_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(song_id='SOGOSOV12AF72A285E', title='¿Dónde va Chichi?', artist_id='ARGUVEV1187B98BA17', year=1997, duration=313.12934),\n",
       " Row(song_id='SOMZWCG12A8C13C480', title=\"I Didn't Mean To\", artist_id='ARD7TVE1187B99BFB1', year=0, duration=218.93179),\n",
       " Row(song_id='SOUPIRU12A6D4FA1E1', title='Der Kleine Dompfaff', artist_id='ARJIE2Y1187B994AB7', year=0, duration=152.92036),\n",
       " Row(song_id='SOXVLOJ12AB0189215', title='Amor De Cabaret', artist_id='ARKRRTF1187B9984DA', year=0, duration=177.47546),\n",
       " Row(song_id='SOWTBJW12AC468AC6E', title='Broken-Down Merry-Go-Round', artist_id='ARQGYP71187FB44566', year=0, duration=151.84934)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_table.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = input_data + \"log_data/*.json\"\n",
    "\n",
    "df = spark.read.json(log_data)\n",
    "\n",
    "df = df.filter(df.page=='NextSong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"logs_data_table\")\n",
    "# extract columns for users table    \n",
    "users_table = spark.sql('''\n",
    "    SELECT DISTINCT userId, firstName, lastName, gender, level\n",
    "    FROM logs_data_table\n",
    "''')\n",
    "users_table = users_table.dropDuplicates([\"userId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(userId='51', firstName='Maia', lastName='Burke', gender='F', level='free'),\n",
       " Row(userId='7', firstName='Adelyn', lastName='Jordan', gender='F', level='free'),\n",
       " Row(userId='15', firstName='Lily', lastName='Koch', gender='F', level='paid'),\n",
       " Row(userId='54', firstName='Kaleb', lastName='Cook', gender='M', level='free'),\n",
       " Row(userId='101', firstName='Jayden', lastName='Fox', gender='M', level='free')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_table.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"ts\",from_unixtime((df.ts.cast('bigint')/1000)).cast('timestamp'))\n",
    "df.createOrReplaceTempView(\"time_table\")\n",
    "time_table = df.select(\\\n",
    "              df.ts.alias('start_time'),    \n",
    "              hour(df.ts).alias('hour'), \\\n",
    "              dayofmonth(df.ts).alias('day'),\\\n",
    "              weekofyear(df.ts).alias('week'),\\\n",
    "              month(df.ts).alias('month'),\\\n",
    "              year(df.ts).alias('year'),\\\n",
    "              dayofweek(df.ts).alias('weekday'),\\\n",
    "            )\n",
    "\n",
    "time_table = time_table.dropDuplicates([\"start_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(start_time=datetime.datetime(2018, 11, 21, 18, 52, 12), hour=18, day=21, week=47, month=11, year=2018, weekday=4),\n",
       " Row(start_time=datetime.datetime(2018, 11, 22, 3, 46, 29), hour=3, day=22, week=47, month=11, year=2018, weekday=5),\n",
       " Row(start_time=datetime.datetime(2018, 11, 14, 12, 37, 40), hour=12, day=14, week=46, month=11, year=2018, weekday=4),\n",
       " Row(start_time=datetime.datetime(2018, 11, 14, 20, 14, 41), hour=20, day=14, week=46, month=11, year=2018, weekday=4),\n",
       " Row(start_time=datetime.datetime(2018, 11, 15, 7, 3), hour=7, day=15, week=46, month=11, year=2018, weekday=5)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_table.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data = input_data + \"song_data/*/*/*/*.json\"\n",
    "song_df = spark.read.json(song_data, schema=songsSchema)\n",
    "song_df.createOrReplaceTempView(\"songs_table\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_table = spark.sql('''\n",
    "    SELECT DISTINCT artist_id, artist_name AS name, artist_location AS location, artist_latitude AS latitude, artist_longitude AS longitude\n",
    "    FROM songs_table\n",
    "''')\n",
    "artists_table.createOrReplaceTempView(\"artists_table\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=2018, month=11, start_time=datetime.datetime(2018, 11, 22, 5, 56, 47), user_id='15', level='paid', song_id='SOZCTXZ12AB0182364', artist_id='AR5KOSW1187FB35FF4', session_id=818, location='Chicago-Naperville-Elgin, IL-IN-WI', user_agent='\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"', songplay_id=0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songplays_table = spark.sql('''\n",
    "        SELECT \n",
    "            year(l.ts) AS year,\n",
    "            month(l.ts) AS month,\n",
    "            l.ts AS start_time,\n",
    "            l.userId AS user_id,\n",
    "            l.level,\n",
    "            s.song_id,\n",
    "            a.artist_id,\n",
    "            l.sessionId AS session_id,\n",
    "            l.location,\n",
    "            l.userAgent AS user_agent\n",
    "        FROM time_table AS l\n",
    "        JOIN songs_table AS s \n",
    "        ON (l.song = s.title AND l.artist = s.artist_name)  \n",
    "        JOIN artists_table AS a ON a.artist_id=s.artist_id\n",
    "        LIMIT 5\n",
    "    ''')\n",
    "songplays_table = songplays_table.withColumn(\"songplay_id\", monotonically_increasing_id())\n",
    "songplays_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}